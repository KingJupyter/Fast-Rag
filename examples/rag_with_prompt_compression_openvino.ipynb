{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b1aeaea-43d9-476b-8fce-5c4b55707874",
   "metadata": {},
   "source": [
    "# Run RAG with Prompt Compression + OpenVINO \n",
    "\n",
    "this tutorial, we will demo how to build a RAG pipeline running with [LLMLingua](https://github.com/microsoft/LLMLingua) prompt compression model, quantized with [OpenVINO](https://docs.openvino.ai/2024/home.html).\n",
    "\n",
    "We will use a pipeline that will:\n",
    "\n",
    "- Fetch relevant documents for our question.\n",
    "- Rerank the documents for better performance.\n",
    "- Compress the documents returned or the prompt itself.\n",
    "- Run the LLM to answer the question.\n",
    "\n",
    "For more information about LLMLinga, we refer to the [original repository](https://github.com/microsoft/LLMLingua)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba170174-1b72-4639-8d11-70ba9541ad6e",
   "metadata": {},
   "source": [
    "## RAG Pipeline Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb51e32-c066-418c-a021-73a3e3f13f1f",
   "metadata": {},
   "source": [
    "Now that our model is quantized, we can create a RAG pipeline with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c25d1abb-1e57-4290-8a6e-43aa20ceca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from haystack import Pipeline, Document\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack.components.builders.answer_builder import AnswerBuilder\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.components.rankers import TransformersSimilarityRanker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1cfe9c-7861-4ed8-836e-689a612faf15",
   "metadata": {},
   "source": [
    "We start from a collection of paragraphs from Wikipedia, for the retrieval phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23442f1b-ede3-4ef8-9768-d0e598315cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_collection = [{'id': '11457596',\n",
    "  'text': 'Quest\", the \"Ultima\" series, \"EverQuest\", the \"Warcraft\" series, and the \"Elder Scrolls\" series of games as well as video games set in Middle-earth itself. Research also suggests that some consumers of fantasy games derive their motivation from trying to create an epic fantasy narrative which is influenced by \"The Lord of the Rings\". In 1965, songwriter Donald Swann, who was best known for his collaboration with Michael Flanders as Flanders & Swann, set six poems from \"The Lord of the Rings\" and one from \"The Adventures of Tom Bombadil\" (\"Errantry\") to music. When Swann met with Tolkien to play the',\n",
    "  'title': 'The Lord of the Rings'},\n",
    " {'id': '11457582',\n",
    "  'text': 'helped \"The Lord of the Rings\" become immensely popular in the United States in the 1960s. The book has remained so ever since, ranking as one of the most popular works of fiction of the twentieth century, judged by both sales and reader surveys. In the 2003 \"Big Read\" survey conducted in Britain by the BBC, \"The Lord of the Rings\" was found to be the \"Nation\\'s best-loved book\". In similar 2004 polls both Germany and Australia also found \"The Lord of the Rings\" to be their favourite book. In a 1999 poll of Amazon.com customers, \"The Lord of the',\n",
    "  'title': 'The Lord of the Rings'},\n",
    " {'id': '11457540',\n",
    "  'text': 'of Tolkien\\'s works is such that the use of the words \"Tolkienian\" and \"Tolkienesque\" has been recorded in the \"Oxford English Dictionary\". The enduring popularity of \"The Lord of the Rings\" has led to numerous references in popular culture, the founding of many societies by fans of Tolkien\\'s works, and the publication of many books about Tolkien and his works. \"The Lord of the Rings\" has inspired, and continues to inspire, artwork, music, films and television, video games, board games, and subsequent literature. Award-winning adaptations of \"The Lord of the Rings\" have been made for radio, theatre, and film. In',\n",
    "  'title': 'The Lord of the Rings'},\n",
    " {'id': '11457587',\n",
    "  'text': 'has been read as fitting the model of Joseph Campbell\\'s \"monomyth\". \"The Lord of the Rings\" has been adapted for film, radio and stage. The book has been adapted for radio four times. In 1955 and 1956, the BBC broadcast \"The Lord of the Rings\", a 13-part radio adaptation of the story. In the 1960s radio station WBAI produced a short radio adaptation. A 1979 dramatization of \"The Lord of the Rings\" was broadcast in the United States and subsequently issued on tape and CD. In 1981, the BBC broadcast \"The Lord of the Rings\", a new dramatization in 26',\n",
    "  'title': 'The Lord of the Rings'},\n",
    " {'id': '11457592',\n",
    "  'text': '\"The Lord of the Rings\", was released on the internet in May 2009 and has been covered in major media. \"Born of Hope\", written by Paula DiSante, directed by Kate Madison, and released in December 2009, is a fan film based upon the appendices of \"The Lord of the Rings\". In November 2017, Amazon acquired the global television rights to \"The Lord of the Rings\", committing to a multi-season television series. The series will not be a direct adaptation of the books, but will instead introduce new stories that are set before \"The Fellowship of the Ring\". Amazon said the',\n",
    "  'title': 'The Lord of the Rings'},\n",
    " {'id': '7733817',\n",
    "  'text': 'The Lord of the Rings Online The Lord of the Rings Online: Shadows of Angmar is a massive multiplayer online role-playing game (MMORPG) for Microsoft Windows and OS X set in a fantasy universe based upon J. R. R. Tolkien\\'s Middle-earth writings, taking place during the time period of \"The Lord of the Rings\". It launched in North America, Australia, Japan, and Europe in 2007. Originally subscription-based, it is free-to-play, with a paid VIP subscription available that provides players various perks.  The game\\'s environment is based on \"The Lord of the Rings\" and \"The Hobbit\". However, Turbine does not',\n",
    "  'title': 'The Lord of the Rings Online'},\n",
    " {'id': '22198847',\n",
    "  'text': 'of \"The Lord of the Rings\", including Ian McKellen, Andy Serkis, Hugo Weaving, Elijah Wood, Ian Holm, Christopher Lee, Cate Blanchett and Orlando Bloom who reprised their roles. Although the \"Hobbit\" films were even more commercially successful than \"The Lord of the Rings\", they received mixed reviews from critics. Numerous video games were released to supplement the film series. They include: \",\" Pinball, \"\", \"\", , \"\", \"\", \"\", \"\", \"The Lord of the Rings Online\", \"\", \"\", \"\", \"Lego The Lord of the Rings\", \"Guardians of Middle-earth\", \"\", and \"\".',\n",
    "  'title': 'The Lord of the Rings (film series)'},\n",
    " {'id': '24071573',\n",
    "  'text': 'Lord of the Rings (musical) The Lord of the Rings is the most prominent of several theatre adaptations of J. R. R. Tolkien\\'s epic high fantasy novel of the same name, with music by A. R. Rahman, Christopher Nightingale and the band Värttinä, and book and lyrics by Matthew Warchus and Shaun McKenna. Set in the world of Middle-earth, \"The Lord of the Rings\" tells the tale of a humble hobbit who is asked to play the hero and undertake a treacherous mission to destroy an evil, magic ring without being seduced by its power. The show was first performed',\n",
    "  'title': 'Lord of the Rings (musical)'},\n",
    " {'id': '11457536',\n",
    "  'text': 'The Lord of the Rings The Lord of the Rings is an epic high fantasy novel written by English author and scholar J. R. R. Tolkien. The story began as a sequel to Tolkien\\'s 1937 fantasy novel \"The Hobbit\", but eventually developed into a much larger work. Written in stages between 1937 and 1949, \"The Lord of the Rings\" is one of the best-selling novels ever written, with over 150 million copies sold. The title of the novel refers to the story\\'s main antagonist, the Dark Lord Sauron, who had in an earlier age created the One Ring to rule',\n",
    "  'title': 'The Lord of the Rings'},\n",
    " {'id': '13304003',\n",
    "  'text': \"The Lord of the Rings (disambiguation) The Lord of the Rings is a fantasy novel by J. R. R. Tolkien. The title refers to Sauron, the story's main antagonist. The Lord of the Rings may also refer to:\",\n",
    "  'title': 'The Lord of the Rings (disambiguation)'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d381c2c-a3ca-4bb8-b003-481d6aed5148",
   "metadata": {},
   "source": [
    "We then create an InMemoryDocumentStore document store, to store all the documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f3e6df-3efa-41c7-a096-11f90b4b9c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = InMemoryDocumentStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99700ae4-fd3f-4d16-ad7c-8cd746c9999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [Document(id=item[\"id\"], content=item[\"text\"], meta={\"title\": item[\"title\"]}) for item in document_collection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2d901a6-a350-45a9-b69e-ab44a4dad9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.write_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6fb8f-eb34-421c-9ceb-32f8df00ec6b",
   "metadata": {},
   "source": [
    "Next, we create a simple BM25 retriever on top of our store, and an additional reranker component to improve the ranking of the documents used for answering the question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "702ce4e4-6a26-473f-9804-91136ddb60e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = InMemoryBM25Retriever(document_store=store)\n",
    " \n",
    "ranker = TransformersSimilarityRanker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5334ce5-48ff-4f09-804e-45bf96e8c2b2",
   "metadata": {},
   "source": [
    "Now that we have created the retrieval components, we move to the LLM usage.\n",
    "\n",
    "We create a document template that contains a placeholder for the retrieved documents to be inserted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "007a35c9-c876-4616-9b1a-455a321195d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a RAG pipeline\n",
    "prompt_template = \"\"\"\n",
    "Given these documents, answer the question.\n",
    "Documents:\n",
    "{% for doc in documents %}\n",
    "    {{ doc.content }}\n",
    "{% endfor %}\n",
    "Question: {{query}}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f320633-f069-44c5-bb00-7decc3cbb749",
   "metadata": {},
   "source": [
    "Next, we use the ```HuggingFaceLocalGenerator``` to load an LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab846eb2-8774-4064-8af8-61e9ced9dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.generators import HuggingFaceLocalGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae9d9631-1ce8-4019-9d30-31dacf5f8950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator = HuggingFaceLocalGenerator(\n",
    "    model=\"microsoft/phi-2\",\n",
    "    task=\"text-generation\",\n",
    "    generation_kwargs={\n",
    "        \"max_new_tokens\": 100,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eda2552-654e-49a0-b1e8-050291b2c781",
   "metadata": {},
   "source": [
    "# Prompt Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf0461a-20df-4ba4-bc8e-c3ae1ded02eb",
   "metadata": {},
   "source": [
    "To compress our prompt, we will also utilize```OVLLMLinguaPromptCompressor```, to speed up the compression.\n",
    "\n",
    "First, we quantize the LLMLingua model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef35d25-df98-4ec8-af77-8f4786a1d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from optimum.intel import OVQuantizer, OVModelForTokenClassification\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "model_id = \"microsoft/llmlingua-2-xlm-roberta-large-meetingbank\"\n",
    "model = OVModelForTokenClassification.from_pretrained(model_id, export=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "def preprocess_fn(examples, tokenizer):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence\"], padding=True, truncation=True, max_length=128\n",
    "    )\n",
    "\n",
    "quantizer = OVQuantizer.from_pretrained(model)\n",
    "calibration_dataset = quantizer.get_calibration_dataset(\n",
    "    \"glue\",\n",
    "    dataset_config_name=\"sst2\",\n",
    "    preprocess_function=partial(preprocess_fn, tokenizer=tokenizer),\n",
    "    num_samples=200,\n",
    "    dataset_split=\"train\",\n",
    "    preprocess_batch=True,\n",
    ")\n",
    "# The directory where the quantized model will be saved\n",
    "save_dir = \"nncf_results\"\n",
    "# Apply static quantization and save the resulting model in the OpenVINO IR format\n",
    "quantizer.quantize(calibration_dataset=calibration_dataset, save_directory=save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a9cb84-1f64-48a3-b39b-5e79ed110199",
   "metadata": {},
   "source": [
    "For more information about model quantization, we refer to the [optimum-intel](https://github.com/huggingface/optimum-intel) repo.\n",
    "\n",
    "Now that our model has been quantized, we can load it in our OVLLMLinguaPromptCompressor component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5b92a6c-ad45-4e45-97b3-2686bf4eee89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, onnx, openvino\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from fastrag.prompt_compressors.ov_llm_lingua import OVLLMLinguaPromptCompressor\n",
    "\n",
    "path_to_quantized_llm_lingua_2 = \"nncf_results\"\n",
    "prompt_compressor = OVLLMLinguaPromptCompressor(path_to_quantized_llm_lingua_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8d05ce-d989-4fda-a9d8-bb056a19f55e",
   "metadata": {},
   "source": [
    "# Pipeline Definition\n",
    "\n",
    "lets compress **only** the input documents, in order to avoid corrupting our question and instructions.\n",
    "\n",
    "So, lets create a main template, and a document template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19423b18-eea5-4e99-a87b-d5e12298c918",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_template = \"\"\"{% for doc in documents %}\n",
    "    {{ doc.content }}\n",
    "{% endfor %}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd6ae5bb-85aa-43e9-a2e6-6199cccfcfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prompt_template = \"\"\"\n",
    "Given these documents, answer the question.\n",
    "Documents:\n",
    "{{documents}}\n",
    "Question: {{query}}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "999ed1a2-e27b-4a1b-a19e-ffacb53413cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline created\n"
     ]
    }
   ],
   "source": [
    "pipe_doc_compress = Pipeline()\n",
    "\n",
    "pipe_doc_compress.add_component(\"retriever\", retriever)\n",
    "pipe_doc_compress.add_component(\"ranker\", ranker)\n",
    "\n",
    "# define a separate docuement builder and compressor\n",
    "pipe_doc_compress.add_component(\"doc_prompt_builder\", PromptBuilder(template=document_template))\n",
    "pipe_doc_compress.add_component(\"doc_compressor\", prompt_compressor)\n",
    "\n",
    "# After compressing the docs, put them in the prompt builder for the LLM :)\n",
    "pipe_doc_compress.add_component(\"llm_prompt_builder\", PromptBuilder(template=full_prompt_template))\n",
    "pipe_doc_compress.add_component(\"llm\", generator)\n",
    "\n",
    "# BUILD PIPELINE\n",
    "\n",
    "pipe_doc_compress.connect(\"retriever.documents\", \"ranker.documents\")\n",
    "\n",
    "# Compress the documents\n",
    "pipe_doc_compress.connect(\"ranker\", \"doc_prompt_builder.documents\")\n",
    "pipe_doc_compress.connect(\"doc_prompt_builder\", \"doc_compressor.prompt\")\n",
    "\n",
    "# Insert the compressed documents into the prompt builder\n",
    "pipe_doc_compress.connect(\"doc_compressor\", \"llm_prompt_builder.documents\")\n",
    "\n",
    "# Give our LLM the new prompt\n",
    "pipe_doc_compress.connect(\"llm_prompt_builder\", \"llm\")\n",
    "\n",
    "print(\"Pipeline created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "969bc9b1-4f64-4256-b73a-acbaec26453a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the model to CPU ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be75c921b7b4462eaaef833e42c33534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2e78c7710149a1a785051fb0e52a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ranking by BM25...:   0%|          | 0/10 [00:00<?, ? docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is the main villan in Lord of the Rings?\"\n",
    "answer_result = pipe_doc_compress.run({\n",
    "    \"llm_prompt_builder\": {\n",
    "        \"query\": query\n",
    "    },\n",
    "    \"retriever\": {\n",
    "        \"query\": query\n",
    "    },\n",
    "    \"ranker\": {\n",
    "        \"query\": query,\n",
    "        \"top_k\": 5\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf5ea8a5-a5d2-4f0f-8575-18a77f7e9b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The main villan in Lord of the Rings is Sauron.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(answer_result[\"llm\"][\"replies\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc79a6d-98c9-4271-b4e9-a1d65f30ac9c",
   "metadata": {},
   "source": [
    "Our answer is correct!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
